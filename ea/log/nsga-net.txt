2020-09-04 15:01:11.260635: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-09-04 15:01:11.287239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 15:01:11.287474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:01:11.289108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:01:11.290406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 15:01:11.290685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 15:01:11.292294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 15:01:11.293093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 15:01:11.296544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:01:11.297656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 15:01:11.298001: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-09-04 15:01:11.322128: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2793165000 Hz
2020-09-04 15:01:11.323251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2b8b4c170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 15:01:11.323299: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 15:01:11.324202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 15:01:11.324267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:01:11.324312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:01:11.324352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 15:01:11.324392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 15:01:11.324432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 15:01:11.324471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 15:01:11.324510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:01:11.326000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 15:01:11.326089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:01:11.543696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 15:01:11.543745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 15:01:11.543763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 15:01:11.545558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 15:01:11.547493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2bc2ec9b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-04 15:01:11.547532: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-09-04 15:01:15.757335: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 15:01:15.757498: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 15:01:15.758137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 15:01:15.758200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:01:15.758231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:01:15.758260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 15:01:15.758288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 15:01:15.758316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 15:01:15.758344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 15:01:15.758372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:01:15.758931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 15:01:15.758974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 15:01:15.758988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 15:01:15.758997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 15:01:15.759601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 15:01:15.765017: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 15:01:15.765046: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2020-09-04 15:01:15.765057: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Using TensorFlow backend.
WARNING:tensorflow:From /home/tudo/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4179: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/848.64k flops)
  model/conv2d/Conv2D (110.59k/110.59k flops)
  model/conv2d_3/Conv2D (73.73k/73.73k flops)
  model/conv2d_2/Conv2D (73.73k/73.73k flops)
  model/conv2d_4/Conv2D (73.73k/73.73k flops)
  model/conv2d_7/Conv2D (73.73k/73.73k flops)
  model/conv2d_1/Conv2D (73.73k/73.73k flops)
  model/conv2d_5/Conv2D (73.73k/73.73k flops)
  model/conv2d_6/Conv2D (73.73k/73.73k flops)
  model/conv2d_13/Conv2D (18.43k/18.43k flops)
  model/conv2d_10/Conv2D (18.43k/18.43k flops)
  model/conv2d_15/Conv2D (18.43k/18.43k flops)
  model/conv2d_11/Conv2D (18.43k/18.43k flops)
  model/conv2d_14/Conv2D (18.43k/18.43k flops)
  model/conv2d_8/Conv2D (18.43k/18.43k flops)
  model/conv2d_9/Conv2D (18.43k/18.43k flops)
  model/conv2d_12/Conv2D (18.43k/18.43k flops)
  model/batch_normalization_4/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_7/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_6/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_5/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_3/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_2/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_1/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization/FusedBatchNormV3 (4.11k/4.11k flops)
  model/dense/MatMul (2.56k/2.56k flops)
  model/conv2d_4/BiasAdd (2.05k/2.05k flops)
  model/add_1/add (2.05k/2.05k flops)
  model/conv2d_3/BiasAdd (2.05k/2.05k flops)
  model/conv2d_5/BiasAdd (2.05k/2.05k flops)
  model/conv2d_2/BiasAdd (2.05k/2.05k flops)
  model/conv2d_6/BiasAdd (2.05k/2.05k flops)
  model/conv2d_7/BiasAdd (2.05k/2.05k flops)
  model/max_pooling2d/MaxPool (2.05k/2.05k flops)
  model/add/add (2.05k/2.05k flops)
  model/add_2/add (2.05k/2.05k flops)
  model/conv2d_1/BiasAdd (2.05k/2.05k flops)
  model/conv2d/BiasAdd (2.05k/2.05k flops)
  model/batch_normalization_10/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_11/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_9/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_8/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_15/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_14/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_13/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_12/FusedBatchNormV3 (1.04k/1.04k flops)
  model/add_4/add (512/512 flops)
  model/max_pooling2d_1/MaxPool (512/512 flops)
  model/conv2d_9/BiasAdd (512/512 flops)
  model/add_3/add (512/512 flops)
  model/conv2d_13/BiasAdd (512/512 flops)
  model/conv2d_8/BiasAdd (512/512 flops)
  model/add_5/add (512/512 flops)
  model/conv2d_10/BiasAdd (512/512 flops)
  model/conv2d_11/BiasAdd (512/512 flops)
  model/conv2d_15/BiasAdd (512/512 flops)
  model/conv2d_12/BiasAdd (512/512 flops)
  model/conv2d_14/BiasAdd (512/512 flops)
  model/dense/Softmax (50/50 flops)
  model/dense/BiasAdd (10/10 flops)

======================End of Report==========================
2020-09-04 15:01:18.871980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:01:19.061482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:01:19.846009: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
Epoch 1/25
1563/1563 - 19s - loss: 2.2052 - accuracy: 0.1697
Epoch 2/25
1563/1563 - 19s - loss: 2.0201 - accuracy: 0.2478
Epoch 3/25
1563/1563 - 18s - loss: 1.9559 - accuracy: 0.2677
Epoch 4/25
1563/1563 - 19s - loss: 1.8850 - accuracy: 0.2998
Epoch 5/25
1563/1563 - 19s - loss: 1.8048 - accuracy: 0.3313
Epoch 6/25
1563/1563 - 18s - loss: 1.7486 - accuracy: 0.3570
Epoch 7/25
1563/1563 - 19s - loss: 1.7171 - accuracy: 0.3701
Epoch 8/25
1563/1563 - 19s - loss: 1.6940 - accuracy: 0.3758
Epoch 9/25
1563/1563 - 18s - loss: 1.6787 - accuracy: 0.3824
Epoch 10/25
1563/1563 - 19s - loss: 1.6637 - accuracy: 0.3909
Epoch 11/25
1563/1563 - 19s - loss: 1.6550 - accuracy: 0.3908
Epoch 12/25
1563/1563 - 19s - loss: 1.6419 - accuracy: 0.3977
Epoch 13/25
1563/1563 - 19s - loss: 1.6409 - accuracy: 0.3970
Epoch 14/25
1563/1563 - 19s - loss: 1.6297 - accuracy: 0.4057
Epoch 15/25
1563/1563 - 19s - loss: 1.6265 - accuracy: 0.4034
Epoch 16/25
1563/1563 - 19s - loss: 1.6138 - accuracy: 0.4095
Epoch 17/25
1563/1563 - 19s - loss: 1.6128 - accuracy: 0.4070
Epoch 18/25
1563/1563 - 19s - loss: 1.6112 - accuracy: 0.4063
Epoch 19/25
1563/1563 - 19s - loss: 1.6059 - accuracy: 0.4100
Epoch 20/25
1563/1563 - 17s - loss: 1.5987 - accuracy: 0.4138
Epoch 21/25
1563/1563 - 16s - loss: 1.5981 - accuracy: 0.4135
Epoch 22/25
1563/1563 - 16s - loss: 1.5956 - accuracy: 0.4131
Epoch 23/25
1563/1563 - 16s - loss: 1.5943 - accuracy: 0.4140
Epoch 24/25
1563/1563 - 16s - loss: 1.5930 - accuracy: 0.4199
Epoch 25/25
1563/1563 - 17s - loss: 1.5891 - accuracy: 0.4164
  1/313 [..............................] - ETA: 0s - loss: 1.5357 - accuracy: 0.4062 16/313 [>.............................] - ETA: 0s - loss: 1.6258 - accuracy: 0.4082 30/313 [=>............................] - ETA: 0s - loss: 1.6484 - accuracy: 0.4073 43/313 [===>..........................] - ETA: 0s - loss: 1.6313 - accuracy: 0.4222 54/313 [====>.........................] - ETA: 0s - loss: 1.6361 - accuracy: 0.4282 67/313 [=====>........................] - ETA: 0s - loss: 1.6404 - accuracy: 0.4240 79/313 [======>.......................] - ETA: 0s - loss: 1.6386 - accuracy: 0.4241 94/313 [========>.....................] - ETA: 0s - loss: 1.6522 - accuracy: 0.4219109/313 [=========>....................] - ETA: 0s - loss: 1.6531 - accuracy: 0.4189123/313 [==========>...................] - ETA: 0s - loss: 1.6550 - accuracy: 0.4190138/313 [============>.................] - ETA: 0s - loss: 1.6575 - accuracy: 0.4160153/313 [=============>................] - ETA: 0s - loss: 1.6541 - accuracy: 0.4171168/313 [===============>..............] - ETA: 0s - loss: 1.6530 - accuracy: 0.4163182/313 [================>.............] - ETA: 0s - loss: 1.6549 - accuracy: 0.4159197/313 [=================>............] - ETA: 0s - loss: 1.6562 - accuracy: 0.4156210/313 [===================>..........] - ETA: 0s - loss: 1.6583 - accuracy: 0.4138223/313 [====================>.........] - ETA: 0s - loss: 1.6661 - accuracy: 0.4126238/313 [=====================>........] - ETA: 0s - loss: 1.6588 - accuracy: 0.4135253/313 [=======================>......] - ETA: 0s - loss: 1.6543 - accuracy: 0.4144267/313 [========================>.....] - ETA: 0s - loss: 1.6613 - accuracy: 0.4132282/313 [==========================>...] - ETA: 0s - loss: 1.6638 - accuracy: 0.4135297/313 [===========================>..] - ETA: 0s - loss: 1.6638 - accuracy: 0.4132312/313 [============================>.] - ETA: 0s - loss: 1.6610 - accuracy: 0.4139313/313 [==============================] - 1s 4ms/step - loss: 1.6611 - accuracy: 0.4139
2020-09-04 15:09:00.287169: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 15:09:00.287294: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 15:09:00.287968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 15:09:00.288030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:09:00.288063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:09:00.288096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 15:09:00.288127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 15:09:00.288159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 15:09:00.288190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 15:09:00.288222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:09:00.288816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 15:09:00.288859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 15:09:00.288871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 15:09:00.288881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 15:09:00.289523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 15:09:00.294441: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 15:09:00.294470: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-09-04 15:09:00.294491: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/12.35m flops)
  model_1/conv2d_19/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_18/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_20/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_17/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_22/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_23/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_16/Conv2D (497.66k/497.66k flops)
  model_1/conv2d_26/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_24/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_25/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_27/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_28/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_30/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_31/Conv2D (373.25k/373.25k flops)
  model_1/batch_normalization_23/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_22/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_20/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_19/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_18/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_17/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_16/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/dense_1/MatMul (11.52k/11.52k flops)
  model_1/add_9/add (9.22k/9.22k flops)
  model_1/conv2d_23/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_22/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_20/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_18/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_17/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_16/BiasAdd (9.22k/9.22k flops)
  model_1/average_pooling2d/AvgPool (9.22k/9.22k flops)
  model_1/conv2d_19/BiasAdd (9.22k/9.22k flops)
  model_1/batch_normalization_26/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_24/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_25/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_27/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_28/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_30/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_31/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/conv2d_25/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_26/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_27/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_24/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_28/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_30/BiasAdd (2.30k/2.30k flops)
  model_1/average_pooling2d_1/AvgPool (2.30k/2.30k flops)
  model_1/conv2d_31/BiasAdd (2.30k/2.30k flops)
  model_1/add_13/add (2.30k/2.30k flops)
  model_1/dense_1/Softmax (50/50 flops)
  model_1/dense_1/BiasAdd (10/10 flops)

======================End of Report==========================
Epoch 1/25
1563/1563 - 15s - loss: 1.7280 - accuracy: 0.3605
Epoch 2/25
1563/1563 - 14s - loss: 1.4106 - accuracy: 0.4847
Epoch 3/25
1563/1563 - 15s - loss: 1.2721 - accuracy: 0.5403
Epoch 4/25
1563/1563 - 16s - loss: 1.1751 - accuracy: 0.5778
Epoch 5/25
1563/1563 - 16s - loss: 1.1128 - accuracy: 0.6009
Epoch 6/25
1563/1563 - 16s - loss: 1.0602 - accuracy: 0.6197
Epoch 7/25
1563/1563 - 17s - loss: 1.0250 - accuracy: 0.6312
Epoch 8/25
1563/1563 - 17s - loss: 0.9989 - accuracy: 0.6413
Epoch 9/25
1563/1563 - 17s - loss: 0.9799 - accuracy: 0.6502
Epoch 10/25
1563/1563 - 16s - loss: 0.9550 - accuracy: 0.6599
Epoch 11/25
1563/1563 - 17s - loss: 0.9450 - accuracy: 0.6630
Epoch 12/25
1563/1563 - 17s - loss: 0.9309 - accuracy: 0.6687
Epoch 13/25
1563/1563 - 16s - loss: 0.9153 - accuracy: 0.6724
Epoch 14/25
1563/1563 - 17s - loss: 0.9058 - accuracy: 0.6765
Epoch 15/25
1563/1563 - 17s - loss: 0.8951 - accuracy: 0.6795
Epoch 16/25
1563/1563 - 17s - loss: 0.8828 - accuracy: 0.6851
Epoch 17/25
1563/1563 - 17s - loss: 0.8739 - accuracy: 0.6877
Epoch 18/25
1563/1563 - 17s - loss: 0.8619 - accuracy: 0.6928
Epoch 19/25
1563/1563 - 17s - loss: 0.8610 - accuracy: 0.6943
Epoch 20/25
1563/1563 - 17s - loss: 0.8523 - accuracy: 0.6959
Epoch 21/25
1563/1563 - 17s - loss: 0.8467 - accuracy: 0.6990
Epoch 22/25
1563/1563 - 17s - loss: 0.8410 - accuracy: 0.7005
Epoch 23/25
1563/1563 - 17s - loss: 0.8308 - accuracy: 0.7039
Epoch 24/25
1563/1563 - 17s - loss: 0.8257 - accuracy: 0.7058
Epoch 25/25
1563/1563 - 17s - loss: 0.8193 - accuracy: 0.7085
  1/313 [..............................] - ETA: 0s - loss: 0.8569 - accuracy: 0.5938 13/313 [>.............................] - ETA: 1s - loss: 1.0517 - accuracy: 0.6274 25/313 [=>............................] - ETA: 1s - loss: 1.0433 - accuracy: 0.6363 39/313 [==>...........................] - ETA: 1s - loss: 1.0373 - accuracy: 0.6410 53/313 [====>.........................] - ETA: 1s - loss: 1.0174 - accuracy: 0.6427 69/313 [=====>........................] - ETA: 0s - loss: 1.0331 - accuracy: 0.6377 85/313 [=======>......................] - ETA: 0s - loss: 1.0589 - accuracy: 0.6342100/313 [========>.....................] - ETA: 0s - loss: 1.0613 - accuracy: 0.6316115/313 [==========>...................] - ETA: 0s - loss: 1.0709 - accuracy: 0.6307127/313 [===========>..................] - ETA: 0s - loss: 1.0695 - accuracy: 0.6339142/313 [============>.................] - ETA: 0s - loss: 1.0671 - accuracy: 0.6353156/313 [=============>................] - ETA: 0s - loss: 1.0584 - accuracy: 0.6392171/313 [===============>..............] - ETA: 0s - loss: 1.0589 - accuracy: 0.6387183/313 [================>.............] - ETA: 0s - loss: 1.0559 - accuracy: 0.6405198/313 [=================>............] - ETA: 0s - loss: 1.0511 - accuracy: 0.6409214/313 [===================>..........] - ETA: 0s - loss: 1.0560 - accuracy: 0.6400230/313 [=====================>........] - ETA: 0s - loss: 1.0512 - accuracy: 0.6416243/313 [======================>.......] - ETA: 0s - loss: 1.0500 - accuracy: 0.6412258/313 [=======================>......] - ETA: 0s - loss: 1.0544 - accuracy: 0.6394274/313 [=========================>....] - ETA: 0s - loss: 1.0602 - accuracy: 0.6367291/313 [==========================>...] - ETA: 0s - loss: 1.0635 - accuracy: 0.6363304/313 [============================>.] - ETA: 0s - loss: 1.0626 - accuracy: 0.6365313/313 [==============================] - 1s 4ms/step - loss: 1.0633 - accuracy: 0.6368
2020-09-04 15:15:54.410017: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 15:15:54.410140: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 15:15:54.410783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 15:15:54.410841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 15:15:54.410871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 15:15:54.410900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 15:15:54.410942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 15:15:54.410985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 15:15:54.411017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 15:15:54.411046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 15:15:54.411682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 15:15:54.411722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 15:15:54.411734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 15:15:54.411744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 15:15:54.412419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6355 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 15:15:54.417366: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 15:15:54.417395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 15:15:54.417406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/772.22m flops)
  model_2/conv2d_33/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_34/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_35/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_36/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_38/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_39/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_47/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_41/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_46/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_44/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_43/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_42/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_40/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_32/Conv2D (4.31m/4.31m flops)
  model_2/batch_normalization_34/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_35/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_36/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_38/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_39/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_33/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_32/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/conv2d_38/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_36/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_39/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_35/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_34/BiasAdd (79.87k/79.87k flops)
  model_2/add_16/add (79.87k/79.87k flops)
  model_2/conv2d_32/BiasAdd (79.87k/79.87k flops)
  model_2/add_18/add (79.87k/79.87k flops)
  model_2/conv2d_33/BiasAdd (79.87k/79.87k flops)
  model_2/add_17/add (79.87k/79.87k flops)
  model_2/add_14/add (79.87k/79.87k flops)
  model_2/average_pooling2d_2/AvgPool (37.75k/37.75k flops)
  model_2/dense_2/MatMul (24.96k/24.96k flops)
  model_2/batch_normalization_41/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_40/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_42/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_43/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_44/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_46/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_47/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/add_22/add (9.44k/9.44k flops)
  model_2/conv2d_47/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_46/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_44/BiasAdd (9.44k/9.44k flops)
  model_2/add_19/add (9.44k/9.44k flops)
  model_2/conv2d_43/BiasAdd (9.44k/9.44k flops)
  model_2/add_21/add (9.44k/9.44k flops)
  model_2/conv2d_42/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_41/BiasAdd (9.44k/9.44k flops)
  model_2/add_23/add (9.44k/9.44k flops)
  model_2/conv2d_40/BiasAdd (9.44k/9.44k flops)
  model_2/average_pooling2d_3/AvgPool (4.99k/4.99k flops)
  model_2/dense_2/Softmax (50/50 flops)
  model_2/dense_2/BiasAdd (10/10 flops)

======================End of Report==========================
