2020-09-04 13:41:59.912434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-09-04 13:41:59.947305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:41:59.947565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:41:59.949184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:41:59.950475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:41:59.950750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:41:59.952350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:41:59.953124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:41:59.957140: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:41:59.958693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:41:59.959127: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-09-04 13:41:59.985997: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2793165000 Hz
2020-09-04 13:41:59.986851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c90883c20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-09-04 13:41:59.986888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-09-04 13:41:59.987699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:41:59.987765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:41:59.987806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:41:59.987852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:41:59.987886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:41:59.987916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:41:59.987945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:41:59.987975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:41:59.990313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:41:59.990413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:42:00.199954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:42:00.200004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:42:00.200018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:42:00.201840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:42:00.204031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555c93f56c00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-09-04 13:42:00.204060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1
2020-09-04 13:42:04.395554: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:42:04.395733: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:42:04.396389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:42:04.396452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:42:04.396484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:42:04.396513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:42:04.396542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:42:04.396571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:42:04.396600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:42:04.396629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:42:04.397203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:42:04.397244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:42:04.397257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:42:04.397267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:42:04.397905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:42:04.403441: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:42:04.403471: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2020-09-04 13:42:04.403483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Using TensorFlow backend.
WARNING:tensorflow:From /home/tudo/anaconda3/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4179: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/848.64k flops)
  model/conv2d/Conv2D (110.59k/110.59k flops)
  model/conv2d_3/Conv2D (73.73k/73.73k flops)
  model/conv2d_2/Conv2D (73.73k/73.73k flops)
  model/conv2d_4/Conv2D (73.73k/73.73k flops)
  model/conv2d_7/Conv2D (73.73k/73.73k flops)
  model/conv2d_1/Conv2D (73.73k/73.73k flops)
  model/conv2d_5/Conv2D (73.73k/73.73k flops)
  model/conv2d_6/Conv2D (73.73k/73.73k flops)
  model/conv2d_13/Conv2D (18.43k/18.43k flops)
  model/conv2d_10/Conv2D (18.43k/18.43k flops)
  model/conv2d_15/Conv2D (18.43k/18.43k flops)
  model/conv2d_11/Conv2D (18.43k/18.43k flops)
  model/conv2d_14/Conv2D (18.43k/18.43k flops)
  model/conv2d_8/Conv2D (18.43k/18.43k flops)
  model/conv2d_9/Conv2D (18.43k/18.43k flops)
  model/conv2d_12/Conv2D (18.43k/18.43k flops)
  model/batch_normalization_4/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_7/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_6/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_5/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_3/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_2/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization_1/FusedBatchNormV3 (4.11k/4.11k flops)
  model/batch_normalization/FusedBatchNormV3 (4.11k/4.11k flops)
  model/dense/MatMul (2.56k/2.56k flops)
  model/conv2d_4/BiasAdd (2.05k/2.05k flops)
  model/add_1/add (2.05k/2.05k flops)
  model/conv2d_3/BiasAdd (2.05k/2.05k flops)
  model/conv2d_5/BiasAdd (2.05k/2.05k flops)
  model/conv2d_2/BiasAdd (2.05k/2.05k flops)
  model/conv2d_6/BiasAdd (2.05k/2.05k flops)
  model/conv2d_7/BiasAdd (2.05k/2.05k flops)
  model/max_pooling2d/MaxPool (2.05k/2.05k flops)
  model/add/add (2.05k/2.05k flops)
  model/add_2/add (2.05k/2.05k flops)
  model/conv2d_1/BiasAdd (2.05k/2.05k flops)
  model/conv2d/BiasAdd (2.05k/2.05k flops)
  model/batch_normalization_10/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_11/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_9/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_8/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_15/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_14/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_13/FusedBatchNormV3 (1.04k/1.04k flops)
  model/batch_normalization_12/FusedBatchNormV3 (1.04k/1.04k flops)
  model/add_4/add (512/512 flops)
  model/max_pooling2d_1/MaxPool (512/512 flops)
  model/conv2d_9/BiasAdd (512/512 flops)
  model/add_3/add (512/512 flops)
  model/conv2d_13/BiasAdd (512/512 flops)
  model/conv2d_8/BiasAdd (512/512 flops)
  model/add_5/add (512/512 flops)
  model/conv2d_10/BiasAdd (512/512 flops)
  model/conv2d_11/BiasAdd (512/512 flops)
  model/conv2d_15/BiasAdd (512/512 flops)
  model/conv2d_12/BiasAdd (512/512 flops)
  model/conv2d_14/BiasAdd (512/512 flops)
  model/dense/Softmax (50/50 flops)
  model/dense/BiasAdd (10/10 flops)

======================End of Report==========================
2020-09-04 13:42:07.993875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:42:08.187082: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:42:08.970668: W tensorflow/stream_executor/gpu/asm_compiler.cc:116] *** WARNING *** You are using ptxas 9.1.108, which is older than 9.2.88. ptxas 9.x before 9.2.88 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.

You do not need to update to CUDA 9.2.88; cherry-picking the ptxas binary is sufficient.
1563/1563 - 19s - loss: 2.1255 - accuracy: 0.2020
  1/313 [..............................] - ETA: 0s - loss: 1.9246 - accuracy: 0.2500 13/313 [>.............................] - ETA: 1s - loss: 1.9331 - accuracy: 0.2500 24/313 [=>............................] - ETA: 1s - loss: 1.9581 - accuracy: 0.2435 36/313 [==>...........................] - ETA: 1s - loss: 1.9424 - accuracy: 0.2587 47/313 [===>..........................] - ETA: 1s - loss: 1.9240 - accuracy: 0.2646 60/313 [====>.........................] - ETA: 1s - loss: 1.9200 - accuracy: 0.2641 72/313 [=====>........................] - ETA: 1s - loss: 1.9147 - accuracy: 0.2617 86/313 [=======>......................] - ETA: 0s - loss: 1.9219 - accuracy: 0.2631101/313 [========>.....................] - ETA: 0s - loss: 1.9246 - accuracy: 0.2602114/313 [=========>....................] - ETA: 0s - loss: 1.9234 - accuracy: 0.2612127/313 [===========>..................] - ETA: 0s - loss: 1.9194 - accuracy: 0.2608140/313 [============>.................] - ETA: 0s - loss: 1.9209 - accuracy: 0.2603154/313 [=============>................] - ETA: 0s - loss: 1.9172 - accuracy: 0.2597167/313 [===============>..............] - ETA: 0s - loss: 1.9158 - accuracy: 0.2592180/313 [================>.............] - ETA: 0s - loss: 1.9166 - accuracy: 0.2587193/313 [=================>............] - ETA: 0s - loss: 1.9163 - accuracy: 0.2581206/313 [==================>...........] - ETA: 0s - loss: 1.9178 - accuracy: 0.2574217/313 [===================>..........] - ETA: 0s - loss: 1.9202 - accuracy: 0.2556232/313 [=====================>........] - ETA: 0s - loss: 1.9233 - accuracy: 0.2554244/313 [======================>.......] - ETA: 0s - loss: 1.9208 - accuracy: 0.2549255/313 [=======================>......] - ETA: 0s - loss: 1.9198 - accuracy: 0.2549268/313 [========================>.....] - ETA: 0s - loss: 1.9196 - accuracy: 0.2530282/313 [==========================>...] - ETA: 0s - loss: 1.9196 - accuracy: 0.2533296/313 [===========================>..] - ETA: 0s - loss: 1.9180 - accuracy: 0.2541308/313 [============================>.] - ETA: 0s - loss: 1.9166 - accuracy: 0.2558313/313 [==============================] - 1s 4ms/step - loss: 1.9165 - accuracy: 0.2562
2020-09-04 13:42:31.285292: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:42:31.285415: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:42:31.286032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:42:31.286094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:42:31.286126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:42:31.286158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:42:31.286189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:42:31.286220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:42:31.286251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:42:31.286283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:42:31.286829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:42:31.286877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:42:31.286891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:42:31.286901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:42:31.287491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:42:31.292302: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:42:31.292332: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:42:31.292344: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/12.35m flops)
  model_1/conv2d_19/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_18/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_20/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_17/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_22/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_23/Conv2D (1.49m/1.49m flops)
  model_1/conv2d_16/Conv2D (497.66k/497.66k flops)
  model_1/conv2d_26/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_24/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_25/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_27/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_28/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_30/Conv2D (373.25k/373.25k flops)
  model_1/conv2d_31/Conv2D (373.25k/373.25k flops)
  model_1/batch_normalization_23/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_22/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_20/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_19/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_18/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_17/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/batch_normalization_16/FusedBatchNormV3 (18.49k/18.49k flops)
  model_1/dense_1/MatMul (11.52k/11.52k flops)
  model_1/add_9/add (9.22k/9.22k flops)
  model_1/conv2d_23/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_22/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_20/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_18/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_17/BiasAdd (9.22k/9.22k flops)
  model_1/conv2d_16/BiasAdd (9.22k/9.22k flops)
  model_1/average_pooling2d/AvgPool (9.22k/9.22k flops)
  model_1/conv2d_19/BiasAdd (9.22k/9.22k flops)
  model_1/batch_normalization_26/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_24/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_25/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_27/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_28/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_30/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/batch_normalization_31/FusedBatchNormV3 (4.66k/4.66k flops)
  model_1/conv2d_25/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_26/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_27/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_24/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_28/BiasAdd (2.30k/2.30k flops)
  model_1/conv2d_30/BiasAdd (2.30k/2.30k flops)
  model_1/average_pooling2d_1/AvgPool (2.30k/2.30k flops)
  model_1/conv2d_31/BiasAdd (2.30k/2.30k flops)
  model_1/add_13/add (2.30k/2.30k flops)
  model_1/dense_1/Softmax (50/50 flops)
  model_1/dense_1/BiasAdd (10/10 flops)

======================End of Report==========================
1563/1563 - 19s - loss: 1.7217 - accuracy: 0.3674
  1/313 [..............................] - ETA: 0s - loss: 1.5359 - accuracy: 0.3750 12/313 [>.............................] - ETA: 1s - loss: 1.4916 - accuracy: 0.4609 28/313 [=>............................] - ETA: 1s - loss: 1.5200 - accuracy: 0.4487 43/313 [===>..........................] - ETA: 0s - loss: 1.5035 - accuracy: 0.4462 59/313 [====>.........................] - ETA: 0s - loss: 1.4967 - accuracy: 0.4544 75/313 [======>.......................] - ETA: 0s - loss: 1.4965 - accuracy: 0.4600 87/313 [=======>......................] - ETA: 0s - loss: 1.5115 - accuracy: 0.4529 97/313 [========>.....................] - ETA: 0s - loss: 1.5054 - accuracy: 0.4565112/313 [=========>....................] - ETA: 0s - loss: 1.5047 - accuracy: 0.4579128/313 [===========>..................] - ETA: 0s - loss: 1.5118 - accuracy: 0.4558143/313 [============>.................] - ETA: 0s - loss: 1.5109 - accuracy: 0.4535156/313 [=============>................] - ETA: 0s - loss: 1.5112 - accuracy: 0.4533169/313 [===============>..............] - ETA: 0s - loss: 1.5182 - accuracy: 0.4510185/313 [================>.............] - ETA: 0s - loss: 1.5241 - accuracy: 0.4498198/313 [=================>............] - ETA: 0s - loss: 1.5191 - accuracy: 0.4520211/313 [===================>..........] - ETA: 0s - loss: 1.5178 - accuracy: 0.4516225/313 [====================>.........] - ETA: 0s - loss: 1.5190 - accuracy: 0.4515238/313 [=====================>........] - ETA: 0s - loss: 1.5170 - accuracy: 0.4522253/313 [=======================>......] - ETA: 0s - loss: 1.5140 - accuracy: 0.4532269/313 [========================>.....] - ETA: 0s - loss: 1.5136 - accuracy: 0.4526282/313 [==========================>...] - ETA: 0s - loss: 1.5144 - accuracy: 0.4522293/313 [===========================>..] - ETA: 0s - loss: 1.5107 - accuracy: 0.4525307/313 [============================>.] - ETA: 0s - loss: 1.5073 - accuracy: 0.4523313/313 [==============================] - 1s 4ms/step - loss: 1.5089 - accuracy: 0.4520
2020-09-04 13:42:56.295575: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:42:56.295692: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:42:56.296272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:42:56.296331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:42:56.296362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:42:56.296392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:42:56.296421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:42:56.296450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:42:56.296491: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:42:56.296521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:42:56.297069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:42:56.297113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:42:56.297127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:42:56.297137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:42:56.297730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:42:56.302049: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:42:56.302079: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:42:56.302091: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/772.22m flops)
  model_2/conv2d_33/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_34/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_35/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_36/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_38/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_39/Conv2D (112.14m/112.14m flops)
  model_2/conv2d_47/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_41/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_46/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_44/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_43/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_42/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_40/Conv2D (13.25m/13.25m flops)
  model_2/conv2d_32/Conv2D (4.31m/4.31m flops)
  model_2/batch_normalization_34/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_35/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_36/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_38/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_39/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_33/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/batch_normalization_32/FusedBatchNormV3 (160.21k/160.21k flops)
  model_2/conv2d_38/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_36/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_39/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_35/BiasAdd (79.87k/79.87k flops)
  model_2/conv2d_34/BiasAdd (79.87k/79.87k flops)
  model_2/add_16/add (79.87k/79.87k flops)
  model_2/conv2d_32/BiasAdd (79.87k/79.87k flops)
  model_2/add_18/add (79.87k/79.87k flops)
  model_2/conv2d_33/BiasAdd (79.87k/79.87k flops)
  model_2/add_17/add (79.87k/79.87k flops)
  model_2/add_14/add (79.87k/79.87k flops)
  model_2/average_pooling2d_2/AvgPool (37.75k/37.75k flops)
  model_2/dense_2/MatMul (24.96k/24.96k flops)
  model_2/batch_normalization_41/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_40/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_42/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_43/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_44/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_46/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/batch_normalization_47/FusedBatchNormV3 (19.34k/19.34k flops)
  model_2/add_22/add (9.44k/9.44k flops)
  model_2/conv2d_47/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_46/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_44/BiasAdd (9.44k/9.44k flops)
  model_2/add_19/add (9.44k/9.44k flops)
  model_2/conv2d_43/BiasAdd (9.44k/9.44k flops)
  model_2/add_21/add (9.44k/9.44k flops)
  model_2/conv2d_42/BiasAdd (9.44k/9.44k flops)
  model_2/conv2d_41/BiasAdd (9.44k/9.44k flops)
  model_2/add_23/add (9.44k/9.44k flops)
  model_2/conv2d_40/BiasAdd (9.44k/9.44k flops)
  model_2/average_pooling2d_3/AvgPool (4.99k/4.99k flops)
  model_2/dense_2/Softmax (50/50 flops)
  model_2/dense_2/BiasAdd (10/10 flops)

======================End of Report==========================
1563/1563 - 42s - loss: 1.5283 - accuracy: 0.4480
  1/313 [..............................] - ETA: 0s - loss: 1.8913 - accuracy: 0.4375  7/313 [..............................] - ETA: 2s - loss: 1.9565 - accuracy: 0.4509 13/313 [>.............................] - ETA: 2s - loss: 1.9131 - accuracy: 0.4495 19/313 [>.............................] - ETA: 2s - loss: 1.9536 - accuracy: 0.4391 25/313 [=>............................] - ETA: 2s - loss: 1.9513 - accuracy: 0.4412 31/313 [=>............................] - ETA: 2s - loss: 1.8917 - accuracy: 0.4516 38/313 [==>...........................] - ETA: 2s - loss: 1.9207 - accuracy: 0.4441 44/313 [===>..........................] - ETA: 2s - loss: 1.9267 - accuracy: 0.4382 50/313 [===>..........................] - ETA: 2s - loss: 1.9506 - accuracy: 0.4369 56/313 [====>.........................] - ETA: 2s - loss: 1.9675 - accuracy: 0.4369 63/313 [=====>........................] - ETA: 2s - loss: 1.9906 - accuracy: 0.4291 69/313 [=====>........................] - ETA: 2s - loss: 1.9957 - accuracy: 0.4275 75/313 [======>.......................] - ETA: 2s - loss: 1.9818 - accuracy: 0.4275 82/313 [======>.......................] - ETA: 1s - loss: 1.9890 - accuracy: 0.4230 88/313 [=======>......................] - ETA: 1s - loss: 1.9951 - accuracy: 0.4222 94/313 [========>.....................] - ETA: 1s - loss: 2.0012 - accuracy: 0.4192100/313 [========>.....................] - ETA: 1s - loss: 1.9859 - accuracy: 0.4253106/313 [=========>....................] - ETA: 1s - loss: 1.9850 - accuracy: 0.4269112/313 [=========>....................] - ETA: 1s - loss: 1.9942 - accuracy: 0.4269119/313 [==========>...................] - ETA: 1s - loss: 1.9950 - accuracy: 0.4254125/313 [==========>...................] - ETA: 1s - loss: 1.9830 - accuracy: 0.4277131/313 [===========>..................] - ETA: 1s - loss: 1.9823 - accuracy: 0.4272137/313 [============>.................] - ETA: 1s - loss: 1.9771 - accuracy: 0.4272143/313 [============>.................] - ETA: 1s - loss: 1.9815 - accuracy: 0.4257149/313 [=============>................] - ETA: 1s - loss: 1.9787 - accuracy: 0.4264155/313 [=============>................] - ETA: 1s - loss: 1.9732 - accuracy: 0.4298161/313 [==============>...............] - ETA: 1s - loss: 1.9791 - accuracy: 0.4292167/313 [===============>..............] - ETA: 1s - loss: 1.9851 - accuracy: 0.4272173/313 [===============>..............] - ETA: 1s - loss: 1.9887 - accuracy: 0.4270179/313 [================>.............] - ETA: 1s - loss: 1.9988 - accuracy: 0.4260186/313 [================>.............] - ETA: 1s - loss: 2.0022 - accuracy: 0.4246192/313 [=================>............] - ETA: 1s - loss: 2.0041 - accuracy: 0.4245198/313 [=================>............] - ETA: 0s - loss: 2.0041 - accuracy: 0.4247205/313 [==================>...........] - ETA: 0s - loss: 2.0000 - accuracy: 0.4252211/313 [===================>..........] - ETA: 0s - loss: 2.0081 - accuracy: 0.4231217/313 [===================>..........] - ETA: 0s - loss: 2.0137 - accuracy: 0.4214223/313 [====================>.........] - ETA: 0s - loss: 2.0134 - accuracy: 0.4210230/313 [=====================>........] - ETA: 0s - loss: 2.0061 - accuracy: 0.4223236/313 [=====================>........] - ETA: 0s - loss: 2.0040 - accuracy: 0.4227242/313 [======================>.......] - ETA: 0s - loss: 1.9998 - accuracy: 0.4238248/313 [======================>.......] - ETA: 0s - loss: 2.0046 - accuracy: 0.4230254/313 [=======================>......] - ETA: 0s - loss: 1.9999 - accuracy: 0.4237261/313 [========================>.....] - ETA: 0s - loss: 2.0039 - accuracy: 0.4223268/313 [========================>.....] - ETA: 0s - loss: 2.0050 - accuracy: 0.4225274/313 [=========================>....] - ETA: 0s - loss: 2.0046 - accuracy: 0.4228280/313 [=========================>....] - ETA: 0s - loss: 2.0070 - accuracy: 0.4227287/313 [==========================>...] - ETA: 0s - loss: 2.0064 - accuracy: 0.4226294/313 [===========================>..] - ETA: 0s - loss: 2.0034 - accuracy: 0.4241300/313 [===========================>..] - ETA: 0s - loss: 2.0023 - accuracy: 0.4239306/313 [============================>.] - ETA: 0s - loss: 2.0041 - accuracy: 0.4240313/313 [==============================] - ETA: 0s - loss: 2.0023 - accuracy: 0.4248313/313 [==============================] - 3s 9ms/step - loss: 2.0023 - accuracy: 0.4248
2020-09-04 13:43:45.548745: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:43:45.548882: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:43:45.549483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:43:45.549543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:43:45.549575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:43:45.549605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:43:45.549634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:43:45.549664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:43:45.549694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:43:45.549724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:43:45.550280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:43:45.550325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:43:45.550339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:43:45.550349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:43:45.550988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:43:45.555824: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:43:45.555855: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:43:45.555866: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/1.52b flops)
  model_3/conv2d_51/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_50/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_49/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_52/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_54/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_55/Conv2D (235.36m/235.36m flops)
  model_3/conv2d_58/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_56/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_57/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_59/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_60/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_62/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_63/Conv2D (14.71m/14.71m flops)
  model_3/conv2d_48/Conv2D (6.25m/6.25m flops)
  model_3/batch_normalization_55/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_54/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_52/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_51/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_50/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_49/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/batch_normalization_48/FusedBatchNormV3 (232.10k/232.10k flops)
  model_3/add_27/add (115.71k/115.71k flops)
  model_3/conv2d_55/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_54/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_52/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_50/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_49/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_48/BiasAdd (115.71k/115.71k flops)
  model_3/conv2d_51/BiasAdd (115.71k/115.71k flops)
  model_3/add_24/add (115.71k/115.71k flops)
  model_3/batch_normalization_59/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_56/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_57/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_58/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_60/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_62/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/batch_normalization_63/FusedBatchNormV3 (15.14k/15.14k flops)
  model_3/dense_3/MatMul (9.04k/9.04k flops)
  model_3/conv2d_59/BiasAdd (7.23k/7.23k flops)
  model_3/max_pooling2d_2/MaxPool (7.23k/7.23k flops)
  model_3/conv2d_63/BiasAdd (7.23k/7.23k flops)
  model_3/add_28/add (7.23k/7.23k flops)
  model_3/conv2d_62/BiasAdd (7.23k/7.23k flops)
  model_3/add_31/add (7.23k/7.23k flops)
  model_3/conv2d_60/BiasAdd (7.23k/7.23k flops)
  model_3/conv2d_58/BiasAdd (7.23k/7.23k flops)
  model_3/conv2d_57/BiasAdd (7.23k/7.23k flops)
  model_3/conv2d_56/BiasAdd (7.23k/7.23k flops)
  model_3/max_pooling2d_3/MaxPool (452/452 flops)
  model_3/dense_3/Softmax (50/50 flops)
  model_3/dense_3/BiasAdd (10/10 flops)

======================End of Report==========================
1563/1563 - 55s - loss: 1.4784 - accuracy: 0.4671
  1/313 [..............................] - ETA: 0s - loss: 2.2210 - accuracy: 0.2188  5/313 [..............................] - ETA: 3s - loss: 2.1765 - accuracy: 0.3375  9/313 [..............................] - ETA: 3s - loss: 2.0992 - accuracy: 0.3438 14/313 [>.............................] - ETA: 3s - loss: 2.1082 - accuracy: 0.3393 19/313 [>.............................] - ETA: 3s - loss: 2.1379 - accuracy: 0.3257 23/313 [=>............................] - ETA: 3s - loss: 2.1170 - accuracy: 0.3261 28/313 [=>............................] - ETA: 3s - loss: 2.1105 - accuracy: 0.3292 33/313 [==>...........................] - ETA: 3s - loss: 2.1061 - accuracy: 0.3286 37/313 [==>...........................] - ETA: 3s - loss: 2.1340 - accuracy: 0.3260 42/313 [===>..........................] - ETA: 3s - loss: 2.1384 - accuracy: 0.3259 47/313 [===>..........................] - ETA: 3s - loss: 2.1369 - accuracy: 0.3291 51/313 [===>..........................] - ETA: 3s - loss: 2.1684 - accuracy: 0.3235 56/313 [====>.........................] - ETA: 3s - loss: 2.1579 - accuracy: 0.3265 61/313 [====>.........................] - ETA: 3s - loss: 2.1497 - accuracy: 0.3263 65/313 [=====>........................] - ETA: 3s - loss: 2.1579 - accuracy: 0.3255 70/313 [=====>........................] - ETA: 2s - loss: 2.1561 - accuracy: 0.3272 74/313 [======>.......................] - ETA: 2s - loss: 2.1492 - accuracy: 0.3256 78/313 [======>.......................] - ETA: 2s - loss: 2.1486 - accuracy: 0.3237 83/313 [======>.......................] - ETA: 2s - loss: 2.1583 - accuracy: 0.3219 87/313 [=======>......................] - ETA: 2s - loss: 2.1657 - accuracy: 0.3175 91/313 [=======>......................] - ETA: 2s - loss: 2.1692 - accuracy: 0.3180 96/313 [========>.....................] - ETA: 2s - loss: 2.1673 - accuracy: 0.3193101/313 [========>.....................] - ETA: 2s - loss: 2.1545 - accuracy: 0.3230106/313 [=========>....................] - ETA: 2s - loss: 2.1598 - accuracy: 0.3222110/313 [=========>....................] - ETA: 2s - loss: 2.1640 - accuracy: 0.3222114/313 [=========>....................] - ETA: 2s - loss: 2.1642 - accuracy: 0.3215118/313 [==========>...................] - ETA: 2s - loss: 2.1599 - accuracy: 0.3210122/313 [==========>...................] - ETA: 2s - loss: 2.1647 - accuracy: 0.3194126/313 [===========>..................] - ETA: 2s - loss: 2.1622 - accuracy: 0.3194131/313 [===========>..................] - ETA: 2s - loss: 2.1632 - accuracy: 0.3187135/313 [===========>..................] - ETA: 2s - loss: 2.1584 - accuracy: 0.3192139/313 [============>.................] - ETA: 2s - loss: 2.1560 - accuracy: 0.3201143/313 [============>.................] - ETA: 2s - loss: 2.1490 - accuracy: 0.3215147/313 [=============>................] - ETA: 2s - loss: 2.1547 - accuracy: 0.3202151/313 [=============>................] - ETA: 2s - loss: 2.1534 - accuracy: 0.3208155/313 [=============>................] - ETA: 2s - loss: 2.1534 - accuracy: 0.3208160/313 [==============>...............] - ETA: 1s - loss: 2.1591 - accuracy: 0.3197164/313 [==============>...............] - ETA: 1s - loss: 2.1600 - accuracy: 0.3194168/313 [===============>..............] - ETA: 1s - loss: 2.1643 - accuracy: 0.3179172/313 [===============>..............] - ETA: 1s - loss: 2.1659 - accuracy: 0.3172177/313 [===============>..............] - ETA: 1s - loss: 2.1720 - accuracy: 0.3148181/313 [================>.............] - ETA: 1s - loss: 2.1711 - accuracy: 0.3147186/313 [================>.............] - ETA: 1s - loss: 2.1789 - accuracy: 0.3117191/313 [=================>............] - ETA: 1s - loss: 2.1780 - accuracy: 0.3114195/313 [=================>............] - ETA: 1s - loss: 2.1785 - accuracy: 0.3114199/313 [==================>...........] - ETA: 1s - loss: 2.1792 - accuracy: 0.3120203/313 [==================>...........] - ETA: 1s - loss: 2.1766 - accuracy: 0.3127208/313 [==================>...........] - ETA: 1s - loss: 2.1766 - accuracy: 0.3119212/313 [===================>..........] - ETA: 1s - loss: 2.1768 - accuracy: 0.3126217/313 [===================>..........] - ETA: 1s - loss: 2.1811 - accuracy: 0.3124222/313 [====================>.........] - ETA: 1s - loss: 2.1802 - accuracy: 0.3122227/313 [====================>.........] - ETA: 1s - loss: 2.1798 - accuracy: 0.3124232/313 [=====================>........] - ETA: 1s - loss: 2.1820 - accuracy: 0.3121236/313 [=====================>........] - ETA: 0s - loss: 2.1821 - accuracy: 0.3116240/313 [======================>.......] - ETA: 0s - loss: 2.1783 - accuracy: 0.3121244/313 [======================>.......] - ETA: 0s - loss: 2.1779 - accuracy: 0.3119249/313 [======================>.......] - ETA: 0s - loss: 2.1786 - accuracy: 0.3120254/313 [=======================>......] - ETA: 0s - loss: 2.1737 - accuracy: 0.3134259/313 [=======================>......] - ETA: 0s - loss: 2.1734 - accuracy: 0.3132263/313 [========================>.....] - ETA: 0s - loss: 2.1744 - accuracy: 0.3129268/313 [========================>.....] - ETA: 0s - loss: 2.1768 - accuracy: 0.3126273/313 [=========================>....] - ETA: 0s - loss: 2.1753 - accuracy: 0.3130278/313 [=========================>....] - ETA: 0s - loss: 2.1754 - accuracy: 0.3123283/313 [==========================>...] - ETA: 0s - loss: 2.1767 - accuracy: 0.3124287/313 [==========================>...] - ETA: 0s - loss: 2.1752 - accuracy: 0.3125291/313 [==========================>...] - ETA: 0s - loss: 2.1740 - accuracy: 0.3123296/313 [===========================>..] - ETA: 0s - loss: 2.1775 - accuracy: 0.3119300/313 [===========================>..] - ETA: 0s - loss: 2.1776 - accuracy: 0.3119304/313 [============================>.] - ETA: 0s - loss: 2.1794 - accuracy: 0.3116308/313 [============================>.] - ETA: 0s - loss: 2.1770 - accuracy: 0.3121312/313 [============================>.] - ETA: 0s - loss: 2.1779 - accuracy: 0.3117313/313 [==============================] - 4s 13ms/step - loss: 2.1771 - accuracy: 0.3119
2020-09-04 13:44:49.956436: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:44:49.956566: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:44:49.957208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:44:49.957274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:44:49.957307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:44:49.957337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:44:49.957366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:44:49.957395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:44:49.957424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:44:49.957454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:44:49.958009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:44:49.958054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:44:49.958068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:44:49.958078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:44:49.958667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:44:49.962800: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:44:49.962831: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:44:49.962842: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/772.22m flops)
  model_4/conv2d_65/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_66/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_67/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_68/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_70/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_71/Conv2D (112.14m/112.14m flops)
  model_4/conv2d_79/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_73/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_78/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_76/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_75/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_74/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_72/Conv2D (13.25m/13.25m flops)
  model_4/conv2d_64/Conv2D (4.31m/4.31m flops)
  model_4/batch_normalization_66/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_67/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_68/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_70/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_71/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_65/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/batch_normalization_64/FusedBatchNormV3 (160.21k/160.21k flops)
  model_4/conv2d_70/BiasAdd (79.87k/79.87k flops)
  model_4/conv2d_68/BiasAdd (79.87k/79.87k flops)
  model_4/conv2d_71/BiasAdd (79.87k/79.87k flops)
  model_4/conv2d_67/BiasAdd (79.87k/79.87k flops)
  model_4/conv2d_66/BiasAdd (79.87k/79.87k flops)
  model_4/add_34/add (79.87k/79.87k flops)
  model_4/conv2d_64/BiasAdd (79.87k/79.87k flops)
  model_4/add_36/add (79.87k/79.87k flops)
  model_4/conv2d_65/BiasAdd (79.87k/79.87k flops)
  model_4/add_35/add (79.87k/79.87k flops)
  model_4/add_32/add (79.87k/79.87k flops)
  model_4/average_pooling2d_4/AvgPool (37.75k/37.75k flops)
  model_4/dense_4/MatMul (24.96k/24.96k flops)
  model_4/batch_normalization_73/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_72/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_74/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_75/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_76/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_78/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/batch_normalization_79/FusedBatchNormV3 (19.34k/19.34k flops)
  model_4/add_40/add (9.44k/9.44k flops)
  model_4/conv2d_79/BiasAdd (9.44k/9.44k flops)
  model_4/conv2d_78/BiasAdd (9.44k/9.44k flops)
  model_4/conv2d_76/BiasAdd (9.44k/9.44k flops)
  model_4/add_37/add (9.44k/9.44k flops)
  model_4/conv2d_75/BiasAdd (9.44k/9.44k flops)
  model_4/add_39/add (9.44k/9.44k flops)
  model_4/conv2d_74/BiasAdd (9.44k/9.44k flops)
  model_4/conv2d_73/BiasAdd (9.44k/9.44k flops)
  model_4/add_41/add (9.44k/9.44k flops)
  model_4/conv2d_72/BiasAdd (9.44k/9.44k flops)
  model_4/average_pooling2d_5/AvgPool (4.99k/4.99k flops)
  model_4/dense_4/Softmax (50/50 flops)
  model_4/dense_4/BiasAdd (10/10 flops)

======================End of Report==========================
=================================================================================
|    n_gens  |   n_evals  |error_rate  |     flops  |architecture  |      time  
=================================================================================
|         1  |         4  |[  0.548 123.456]  |[  0.548 123.456]  |[0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1
 1 0 0 1 0 1 1 1]  |   169.061  
1563/1563 - 43s - loss: 1.4702 - accuracy: 0.4703
  1/313 [..............................] - ETA: 0s - loss: 1.2005 - accuracy: 0.5625  7/313 [..............................] - ETA: 2s - loss: 1.2350 - accuracy: 0.5670 13/313 [>.............................] - ETA: 2s - loss: 1.2007 - accuracy: 0.5889 19/313 [>.............................] - ETA: 2s - loss: 1.2170 - accuracy: 0.5789 26/313 [=>............................] - ETA: 2s - loss: 1.2474 - accuracy: 0.5637 32/313 [==>...........................] - ETA: 2s - loss: 1.2116 - accuracy: 0.5742 38/313 [==>...........................] - ETA: 2s - loss: 1.2323 - accuracy: 0.5699 45/313 [===>..........................] - ETA: 2s - loss: 1.2353 - accuracy: 0.5646 51/313 [===>..........................] - ETA: 2s - loss: 1.2571 - accuracy: 0.5594 57/313 [====>.........................] - ETA: 2s - loss: 1.2560 - accuracy: 0.5603 63/313 [=====>........................] - ETA: 2s - loss: 1.2565 - accuracy: 0.5605 69/313 [=====>........................] - ETA: 2s - loss: 1.2516 - accuracy: 0.5607 76/313 [======>.......................] - ETA: 2s - loss: 1.2489 - accuracy: 0.5604 82/313 [======>.......................] - ETA: 2s - loss: 1.2583 - accuracy: 0.5587 88/313 [=======>......................] - ETA: 1s - loss: 1.2597 - accuracy: 0.5586 94/313 [========>.....................] - ETA: 1s - loss: 1.2572 - accuracy: 0.5598100/313 [========>.....................] - ETA: 1s - loss: 1.2558 - accuracy: 0.5581106/313 [=========>....................] - ETA: 1s - loss: 1.2621 - accuracy: 0.5563112/313 [=========>....................] - ETA: 1s - loss: 1.2676 - accuracy: 0.5536118/313 [==========>...................] - ETA: 1s - loss: 1.2724 - accuracy: 0.5514125/313 [==========>...................] - ETA: 1s - loss: 1.2655 - accuracy: 0.5530132/313 [===========>..................] - ETA: 1s - loss: 1.2643 - accuracy: 0.5535138/313 [============>.................] - ETA: 1s - loss: 1.2629 - accuracy: 0.5532144/313 [============>.................] - ETA: 1s - loss: 1.2617 - accuracy: 0.5538150/313 [=============>................] - ETA: 1s - loss: 1.2630 - accuracy: 0.5529156/313 [=============>................] - ETA: 1s - loss: 1.2566 - accuracy: 0.5543162/313 [==============>...............] - ETA: 1s - loss: 1.2597 - accuracy: 0.5527169/313 [===============>..............] - ETA: 1s - loss: 1.2660 - accuracy: 0.5496175/313 [===============>..............] - ETA: 1s - loss: 1.2706 - accuracy: 0.5484181/313 [================>.............] - ETA: 1s - loss: 1.2714 - accuracy: 0.5487187/313 [================>.............] - ETA: 1s - loss: 1.2735 - accuracy: 0.5478193/313 [=================>............] - ETA: 1s - loss: 1.2755 - accuracy: 0.5466199/313 [==================>...........] - ETA: 0s - loss: 1.2696 - accuracy: 0.5482205/313 [==================>...........] - ETA: 0s - loss: 1.2753 - accuracy: 0.5480211/313 [===================>..........] - ETA: 0s - loss: 1.2766 - accuracy: 0.5472217/313 [===================>..........] - ETA: 0s - loss: 1.2777 - accuracy: 0.5462223/313 [====================>.........] - ETA: 0s - loss: 1.2788 - accuracy: 0.5460229/313 [====================>.........] - ETA: 0s - loss: 1.2750 - accuracy: 0.5471235/313 [=====================>........] - ETA: 0s - loss: 1.2743 - accuracy: 0.5473241/313 [======================>.......] - ETA: 0s - loss: 1.2732 - accuracy: 0.5472247/313 [======================>.......] - ETA: 0s - loss: 1.2718 - accuracy: 0.5466253/313 [=======================>......] - ETA: 0s - loss: 1.2703 - accuracy: 0.5466259/313 [=======================>......] - ETA: 0s - loss: 1.2724 - accuracy: 0.5450265/313 [========================>.....] - ETA: 0s - loss: 1.2728 - accuracy: 0.5450271/313 [========================>.....] - ETA: 0s - loss: 1.2746 - accuracy: 0.5452277/313 [=========================>....] - ETA: 0s - loss: 1.2765 - accuracy: 0.5452283/313 [==========================>...] - ETA: 0s - loss: 1.2761 - accuracy: 0.5457289/313 [==========================>...] - ETA: 0s - loss: 1.2731 - accuracy: 0.5460295/313 [===========================>..] - ETA: 0s - loss: 1.2706 - accuracy: 0.5470302/313 [===========================>..] - ETA: 0s - loss: 1.2706 - accuracy: 0.5471308/313 [============================>.] - ETA: 0s - loss: 1.2724 - accuracy: 0.5469313/313 [==============================] - 3s 9ms/step - loss: 1.2731 - accuracy: 0.5465
2020-09-04 13:45:40.459706: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:45:40.459848: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:45:40.460659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:45:40.460743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:45:40.460796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:45:40.460848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:45:40.460902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:45:40.460954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:45:40.461005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:45:40.461056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:45:40.461920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:45:40.461977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:45:40.462002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:45:40.462022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:45:40.462978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:45:40.467784: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:45:40.467817: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:45:40.467838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/12.35m flops)
  model_5/conv2d_83/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_82/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_84/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_81/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_86/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_87/Conv2D (1.49m/1.49m flops)
  model_5/conv2d_80/Conv2D (497.66k/497.66k flops)
  model_5/conv2d_89/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_95/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_88/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_94/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_90/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_91/Conv2D (373.25k/373.25k flops)
  model_5/conv2d_92/Conv2D (373.25k/373.25k flops)
  model_5/batch_normalization_87/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_86/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_84/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_83/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_82/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_81/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/batch_normalization_80/FusedBatchNormV3 (18.49k/18.49k flops)
  model_5/dense_5/MatMul (11.52k/11.52k flops)
  model_5/conv2d_81/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_87/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_86/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_84/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_83/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_82/BiasAdd (9.22k/9.22k flops)
  model_5/conv2d_80/BiasAdd (9.22k/9.22k flops)
  model_5/average_pooling2d_6/AvgPool (9.22k/9.22k flops)
  model_5/add_45/add (9.22k/9.22k flops)
  model_5/batch_normalization_95/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_94/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_92/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_91/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_90/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_89/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/batch_normalization_88/FusedBatchNormV3 (4.66k/4.66k flops)
  model_5/add_49/add (2.30k/2.30k flops)
  model_5/conv2d_95/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_94/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_92/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_91/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_90/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_89/BiasAdd (2.30k/2.30k flops)
  model_5/conv2d_88/BiasAdd (2.30k/2.30k flops)
  model_5/average_pooling2d_7/AvgPool (2.30k/2.30k flops)
  model_5/dense_5/Softmax (50/50 flops)
  model_5/dense_5/BiasAdd (10/10 flops)

======================End of Report==========================
1563/1563 - 17s - loss: 1.6631 - accuracy: 0.3919
  1/313 [..............................] - ETA: 0s - loss: 1.7256 - accuracy: 0.3750 13/313 [>.............................] - ETA: 1s - loss: 1.6556 - accuracy: 0.4159 26/313 [=>............................] - ETA: 1s - loss: 1.7228 - accuracy: 0.3990 38/313 [==>...........................] - ETA: 1s - loss: 1.6412 - accuracy: 0.4285 52/313 [===>..........................] - ETA: 1s - loss: 1.6753 - accuracy: 0.4237 68/313 [=====>........................] - ETA: 0s - loss: 1.6929 - accuracy: 0.4191 83/313 [======>.......................] - ETA: 0s - loss: 1.7077 - accuracy: 0.4191 99/313 [========>.....................] - ETA: 0s - loss: 1.7153 - accuracy: 0.4094114/313 [=========>....................] - ETA: 0s - loss: 1.7267 - accuracy: 0.4084128/313 [===========>..................] - ETA: 0s - loss: 1.7213 - accuracy: 0.4109143/313 [============>.................] - ETA: 0s - loss: 1.7174 - accuracy: 0.4104156/313 [=============>................] - ETA: 0s - loss: 1.7150 - accuracy: 0.4141169/313 [===============>..............] - ETA: 0s - loss: 1.7169 - accuracy: 0.4112184/313 [================>.............] - ETA: 0s - loss: 1.7255 - accuracy: 0.4088199/313 [==================>...........] - ETA: 0s - loss: 1.7256 - accuracy: 0.4083214/313 [===================>..........] - ETA: 0s - loss: 1.7244 - accuracy: 0.4081230/313 [=====================>........] - ETA: 0s - loss: 1.7311 - accuracy: 0.4068247/313 [======================>.......] - ETA: 0s - loss: 1.7290 - accuracy: 0.4062262/313 [========================>.....] - ETA: 0s - loss: 1.7314 - accuracy: 0.4066276/313 [=========================>....] - ETA: 0s - loss: 1.7287 - accuracy: 0.4084288/313 [==========================>...] - ETA: 0s - loss: 1.7281 - accuracy: 0.4079302/313 [===========================>..] - ETA: 0s - loss: 1.7252 - accuracy: 0.4082313/313 [==============================] - 1s 4ms/step - loss: 1.7264 - accuracy: 0.4075
2020-09-04 13:46:03.682178: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:46:03.682291: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:46:03.682918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:46:03.682979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:46:03.683010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:46:03.683040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:46:03.683069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:46:03.683098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:46:03.683127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:46:03.683157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:46:03.683742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:46:03.683785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:46:03.683810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:46:03.683821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:46:03.684458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:46:03.688944: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:46:03.688976: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-09-04 13:46:03.688987: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/848.64k flops)
  model_6/conv2d_96/Conv2D (110.59k/110.59k flops)
  model_6/conv2d_103/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_99/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_98/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_102/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_101/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_100/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_97/Conv2D (73.73k/73.73k flops)
  model_6/conv2d_111/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_104/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_105/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_106/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_107/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_108/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_109/Conv2D (18.43k/18.43k flops)
  model_6/conv2d_110/Conv2D (18.43k/18.43k flops)
  model_6/batch_normalization_96/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_97/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_98/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_99/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_103/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_102/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_101/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/batch_normalization_100/FusedBatchNormV3 (4.11k/4.11k flops)
  model_6/dense_6/MatMul (2.56k/2.56k flops)
  model_6/add_51/add (2.05k/2.05k flops)
  model_6/conv2d_96/BiasAdd (2.05k/2.05k flops)
  model_6/conv2d_97/BiasAdd (2.05k/2.05k flops)
  model_6/conv2d_98/BiasAdd (2.05k/2.05k flops)
  model_6/conv2d_99/BiasAdd (2.05k/2.05k flops)
  model_6/max_pooling2d_4/MaxPool (2.05k/2.05k flops)
  model_6/conv2d_103/BiasAdd (2.05k/2.05k flops)
  model_6/add_50/add (2.05k/2.05k flops)
  model_6/conv2d_102/BiasAdd (2.05k/2.05k flops)
  model_6/add_52/add (2.05k/2.05k flops)
  model_6/conv2d_101/BiasAdd (2.05k/2.05k flops)
  model_6/conv2d_100/BiasAdd (2.05k/2.05k flops)
  model_6/batch_normalization_105/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_106/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_107/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_111/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_108/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_110/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_104/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/batch_normalization_109/FusedBatchNormV3 (1.04k/1.04k flops)
  model_6/add_54/add (512/512 flops)
  model_6/add_55/add (512/512 flops)
  model_6/max_pooling2d_5/MaxPool (512/512 flops)
  model_6/add_53/add (512/512 flops)
  model_6/conv2d_104/BiasAdd (512/512 flops)
  model_6/conv2d_111/BiasAdd (512/512 flops)
  model_6/conv2d_110/BiasAdd (512/512 flops)
  model_6/conv2d_109/BiasAdd (512/512 flops)
  model_6/conv2d_108/BiasAdd (512/512 flops)
  model_6/conv2d_107/BiasAdd (512/512 flops)
  model_6/conv2d_106/BiasAdd (512/512 flops)
  model_6/conv2d_105/BiasAdd (512/512 flops)
  model_6/dense_6/Softmax (50/50 flops)
  model_6/dense_6/BiasAdd (10/10 flops)

======================End of Report==========================
1563/1563 - 21s - loss: 2.2005 - accuracy: 0.1924
  1/313 [..............................] - ETA: 0s - loss: 1.9077 - accuracy: 0.3750 12/313 [>.............................] - ETA: 1s - loss: 1.9701 - accuracy: 0.2812 25/313 [=>............................] - ETA: 1s - loss: 1.9962 - accuracy: 0.2700 37/313 [==>...........................] - ETA: 1s - loss: 1.9994 - accuracy: 0.2686 50/313 [===>..........................] - ETA: 1s - loss: 2.0098 - accuracy: 0.2625 65/313 [=====>........................] - ETA: 0s - loss: 2.0015 - accuracy: 0.2606 80/313 [======>.......................] - ETA: 0s - loss: 1.9974 - accuracy: 0.2680 95/313 [========>.....................] - ETA: 0s - loss: 2.0002 - accuracy: 0.2638110/313 [=========>....................] - ETA: 0s - loss: 2.0042 - accuracy: 0.2608123/313 [==========>...................] - ETA: 0s - loss: 2.0083 - accuracy: 0.2607134/313 [===========>..................] - ETA: 0s - loss: 2.0083 - accuracy: 0.2635148/313 [=============>................] - ETA: 0s - loss: 2.0061 - accuracy: 0.2603161/313 [==============>...............] - ETA: 0s - loss: 2.0057 - accuracy: 0.2609176/313 [===============>..............] - ETA: 0s - loss: 2.0114 - accuracy: 0.2601190/313 [=================>............] - ETA: 0s - loss: 2.0106 - accuracy: 0.2607205/313 [==================>...........] - ETA: 0s - loss: 2.0073 - accuracy: 0.2605220/313 [====================>.........] - ETA: 0s - loss: 2.0095 - accuracy: 0.2578233/313 [=====================>........] - ETA: 0s - loss: 2.0096 - accuracy: 0.2583246/313 [======================>.......] - ETA: 0s - loss: 2.0058 - accuracy: 0.2605259/313 [=======================>......] - ETA: 0s - loss: 2.0039 - accuracy: 0.2615270/313 [========================>.....] - ETA: 0s - loss: 2.0049 - accuracy: 0.2612285/313 [==========================>...] - ETA: 0s - loss: 2.0024 - accuracy: 0.2627300/313 [===========================>..] - ETA: 0s - loss: 2.0001 - accuracy: 0.2637313/313 [==============================] - 1s 4ms/step - loss: 1.9973 - accuracy: 0.2641
2020-09-04 13:46:31.592219: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2020-09-04 13:46:31.592359: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-09-04 13:46:31.593158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-09-04 13:46:31.593243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-09-04 13:46:31.593295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-09-04 13:46:31.593349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-09-04 13:46:31.593402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-09-04 13:46:31.593454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-09-04 13:46:31.593505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-09-04 13:46:31.593555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-09-04 13:46:31.594600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-09-04 13:46:31.594655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-09-04 13:46:31.594680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-09-04 13:46:31.594700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-09-04 13:46:31.595607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6472 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0, compute capability: 6.1)
2020-09-04 13:46:31.599882: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-09-04 13:46:31.599917: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-09-04 13:46:31.599937: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/10.33m flops)
  model_7/conv2d_115/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_114/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_113/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_116/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_118/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_119/Conv2D (1.49m/1.49m flops)
  model_7/conv2d_112/Conv2D (497.66k/497.66k flops)
  model_7/conv2d_121/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_127/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_120/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_126/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_122/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_123/Conv2D (93.31k/93.31k flops)
  model_7/conv2d_124/Conv2D (93.31k/93.31k flops)
  model_7/batch_normalization_119/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_118/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_116/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_115/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_114/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_113/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/batch_normalization_112/FusedBatchNormV3 (18.49k/18.49k flops)
  model_7/conv2d_113/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_119/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_118/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_116/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_115/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_114/BiasAdd (9.22k/9.22k flops)
  model_7/conv2d_112/BiasAdd (9.22k/9.22k flops)
  model_7/add_59/add (9.22k/9.22k flops)
  model_7/average_pooling2d_8/AvgPool (2.30k/2.30k flops)
  model_7/batch_normalization_127/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_126/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_124/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_123/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_122/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_121/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/batch_normalization_120/FusedBatchNormV3 (1.21k/1.21k flops)
  model_7/dense_7/MatMul (720/720 flops)
  model_7/add_63/add (576/576 flops)
  model_7/conv2d_127/BiasAdd (576/576 flops)
  model_7/conv2d_126/BiasAdd (576/576 flops)
  model_7/conv2d_124/BiasAdd (576/576 flops)
  model_7/conv2d_123/BiasAdd (576/576 flops)
  model_7/conv2d_122/BiasAdd (576/576 flops)
  model_7/conv2d_121/BiasAdd (576/576 flops)
  model_7/conv2d_120/BiasAdd (576/576 flops)
  model_7/average_pooling2d_9/AvgPool (144/144 flops)
  model_7/dense_7/Softmax (50/50 flops)
  model_7/dense_7/BiasAdd (10/10 flops)

======================End of Report==========================
